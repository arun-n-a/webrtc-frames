<!DOCTYPE html>
<html>
  <head>
    <title>Webrtc A</title>
    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script src="js/webrtc_adaptor.js"></script>
  </head>
  <body>
    
    <div class="col-sm-12 form-group">
      <canvas id="canvas"></canvas>
      <canvas id="canvasrgba" width="200" height="150"></canvas>
      <p>
         <video id="localVideo"  autoplay controls muted playsinline></video>
     </p>
  </div>
  <script src="/socket.io/socket.io.js"></script>
 <script>
    const width = 480;
    const height = 320;
    const frameRate = 1000/30;

    var frame, aCtx, analyser, microphone, freqs, times, FFTData, vStreamTrack, imageCapture;
    var audioContext = window.AudioContext || window.webkitAudioContext;
    var canvas = document.getElementById('canvas');
    canvas.width=width;
    canvas.height=height;
    var canvasr = document.getElementById('canvasrgba');
    var vid = document.getElementById('localVideo');
    var frameCount = 0;
    

    
    function draw() {
      console.log(frameCount);
 
       if (canvas.getContext && analyser) {
          var ctx = canvas.getContext('2d');
          imageCapture.grabFrame()
          .then(function(imageFrame){
            ctx.drawImage(imageFrame, 0, 0, width, height);
          })
          frame = ctx.getImageData(0, 0, width, height);
          //console.log("canvas one frame: ", frame.data);
          socket.emit('video frames', frame.data);
          
          //var l = frame.data.length / 4;
          //for (var i = 0; i < l; i++) {
            //var grey = (frame.data[i * 4 + 0] + frame.data[i * 4 + 1] + frame.data[i * 4 + 2]) / 3;
            //imageData.data[i * 4 + 0] = grey;
            //imageData.data[i * 4 + 1] = grey;
            //imageData.data[i * 4 + 2] = grey;
           //}
           //console.log(imageData.data)
          //ctx2.putImageData(imageData, 0, 0);
 
          //freqs = new Uint8Array(analyser.frequencyBinCount);
          times = new Uint8Array(analyser.frequencyBinCount);
          //FFTData = new Float32Array(analyser.frequencyBinCount);
          //analyser.getFloatFrequencyData(FFTData);
          analyser.getByteTimeDomainData(times);
          // getByteTimeDomainData
          //console.log(FFTData);
          //console.log("Times: ", times);
          socket.emit('audio frames', times);
          //console.log("freqs: ", freqs);
          return;
       }
    }
        

 
     //update canvas for every 25ms
     setInterval(function() { draw(); }, frameRate);
 
     //capture stream from canvas
     var localStream = canvas.captureStream(frameRate);
     //get audio with getUserMedia
 
     navigator.mediaDevices.getUserMedia(
        {video: true, audio:true}
       ).then(function (stream) {
 
       var video = document.querySelector('video#localVideo');
 
       video.srcObject = stream;
       //add audio track to the localstream which is captured from canvas
      vStreamTrack = stream.getVideoTracks()[0];
      vStreamTrack.applyConstraints({
          width: {min: 300, ideal: width},
          height: {min:200 , ideal: height},
        })
      imageCapture = new ImageCapture(vStreamTrack)
      localStream.addTrack(stream.getAudioTracks()[0]);
 
       video.onloadedmetadata = function(e) {
 
       video.play();
 
       aCtx = new (AudioContext || webkitAudioContext)();
       // aCtx = new AudioContext();
       //console.log("HS actx: ");
       analyser = aCtx.createAnalyser();
       //console.log("analyser*** is: ", analyser);
       // console.log("HS analyser");
       microphone = aCtx.createMediaStreamSource(stream);
       //console.log("HS microphone");
       microphone.connect(window.analyser);
 
    };
 
    //initialize the webRTCAdaptor with the localStream created.
 
    //initWebRTCAdaptor method is implemented below
 
    // initWebRTCAdaptor(localStream);
 
 });
</script>
<script>
      var socket = io();
      socket.on("rec", msg => {
       // console.log("***************************: ", msg);
        var frameDatas = new Uint8ClampedArray(msg);
        //console.log("***frameData is:  ", frameDatas);
        var ctx2 = canvasr.getContext("2d");
        let imageDataa = new ImageData(frameDatas, 200, 150);
        //console.log("emit rec is: ", imageDataa)
        ctx2.putImageData(imageDataa, 0, 0);
      });
  </script>  
  </body>
</html>

